{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa383361",
   "metadata": {},
   "source": [
    "# Revised Seismic Interpretation Analysis\n",
    "\n",
    "## Introduction: Automating Seismic Facies Classification\n",
    "\n",
    "Seismic interpretation, a cornerstone of subsurface exploration and characterization in geophysics, involves analyzing seismic reflection data to understand geological structures, stratigraphy, and fluid content (e.g., Sheng et al., 2025). A key task within this process is **seismic facies classification**, which aims to categorize distinct zones within the seismic volume based on their reflection characteristics (amplitude, frequency, continuity) (e.g., Gao et al., 2025; Chikhaoui & Alfarraj, 2024). These categories, or **facies**, often correspond to different depositional environments or rock types, providing crucial insights for resource exploration and reservoir modeling (e.g., Gao et al., 2025).\n",
    "\n",
    "Traditionally, seismic facies classification relies heavily on manual interpretation by experienced geophysicists, a process that is time-consuming, subjective, and challenging to apply consistently across large 3D seismic volumes (e.g., Sheng et al., 2025; Babikir et al., 2024). Automating this task using machine learning offers the potential for faster, more objective, and reproducible interpretations (e.g., Babikir et al., 2024; Mustafa & AlRegib, 2023).\n",
    "\n",
    "This study investigates the application of deep learning models for automating seismic facies classification using the publicly available F3 block dataset from the Dutch North Sea. Specifically, we aim to answer the following research questions:\n",
    "\n",
    "1.  How effectively can a baseline 3D Convolutional Neural Network (CNN), trained on seismic amplitude patches, classify seismic facies defined by interpreted horizons?\n",
    "2.  Can sequence-based models, specifically a Bidirectional Long Short-Term Memory (BiLSTM) network analyzing individual seismic traces, provide a competitive or complementary approach to patch-based CNNs for this classification task?\n",
    "\n",
    "We will compare the performance of these two distinct deep learning architectures – one focusing on 3D spatial patterns (CNN) and the other on 1D sequential patterns along seismic traces (BiLSTM) – using standard classification metrics.\n",
    "\n",
    "### Related Work\n",
    "\n",
    "Machine learning has been increasingly applied to seismic interpretation tasks (e.g., Sheng et al., 2025; Liu et al., 2025). Early work often utilized traditional methods like support vector machines or decision trees based on handcrafted seismic attributes (a concept discussed in the context of modern attribute selection by Babikir et al., 2024). More recently, deep learning, particularly CNNs, has shown significant promise for tasks like fault detection (e.g., Liu et al., 2025), salt body delineation [Citation for salt body delineation not directly available in the provided list; a general DL review might be needed], and facies classification (e.g., Zhao et al., 2023; Ore & Gao, 2025). Most CNN approaches for facies classification operate on 2D slices or 3D patches extracted from the seismic volume (e.g., Stitt et al., 2022; Durall et al., 2021).\n",
    "\n",
    "Recurrent Neural Networks (RNNs), including LSTMs, have been explored for analyzing seismic data as sequences, often focusing on well log correlation or time-series analysis (e.g., Shi et al., 2020, for waveform embedding which is sequential). Their application specifically for facies classification based on trace sequences within a 3D volume is less common compared to CNNs.\n",
    "\n",
    "This work differentiates itself by directly comparing a standard 3D CNN patch-based approach with a BiLSTM trace-based approach on the same 3D seismic dataset (F3 block) for facies classification defined by multiple horizons, providing insights into the relative strengths of spatial versus sequential modeling for this specific problem.\n",
    "\n",
    "*(Note: The Reinforcement Learning investigation mentioned in previous versions has been removed based on feedback to focus the scope of this study.)*\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Dataset: F3 Block, Dutch North Sea\n",
    "\n",
    "This study utilizes the F3 block seismic dataset, a publicly available 3D seismic survey from the Dutch sector of the North Sea. The data is provided in the standard **SEG-Y format** (`Seismic_data.sgy`), which stores seismic trace data along with header information defining trace locations (inline, crossline, X/Y coordinates) and recording parameters.\n",
    "\n",
    "Accompanying the seismic volume are interpreted **horizons**, provided as text files (`.xyt`). Each file contains X, Y spatial coordinates (Easting, Northing in meters) and the corresponding two-way travel time (TWT in milliseconds) defining a specific geological boundary surface within the seismic volume. These horizons delineate the boundaries between different seismic facies, serving as the ground truth for our classification task.\n",
    "\n",
    "**Table 1: F3 Dataset Summary**\n",
    "\n",
    "| Parameter         | Value                                   |\n",
    "| :---------------- | :-------------------------------------- |\n",
    "| Data Format       | SEG-Y                                   |\n",
    "| Dimensions (ILxXLxSamples) | 651 x 951 x 462                         |\n",
    "| Inline Range      | [Specific Range, e.g., 100-750]         |\n",
    "| Crossline Range   | [Specific Range, e.g., 300-1250]        |\n",
    "| Sample Interval   | 4 ms                                    |\n",
    "| Time Range        | 0 - 1844 ms                             |\n",
    "| Horizon Files     | 5 (`F3-Horizon-FS4.xyt`, etc.)          |\n",
    "| Derived Classes   | 6 (Regions between/outside 5 horizons) |\n",
    "\n",
    "Derived classes are based off of the 5 horizons(fs4, msf4, fs6, fs7, and fs8 respectfully) and a class to be considered not a horizon.\n",
    "\n",
    "\n",
    "*(Note: Specific Inline/Crossline ranges need verification from data loading)*\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "The primary goal of preprocessing is to convert the raw SEG-Y data and horizon picks into labeled data suitable for model training: 3D patches for the CNN and 1D traces for the BiLSTM.\n",
    "\n",
    "1.  **SEG-Y Loading & Coordinate Scaling:**\n",
    "    *   The `segyio` library is used to load the seismic volume, mapping trace headers (Inline, Crossline, CDP_X, CDP_Y) and amplitude samples.\n",
    "    *   Coordinate scaling factors from the SEG-Y binary header are applied to ensure CDP_X/CDP_Y coordinates match the units (meters) of the horizon files.\n",
    "2.  **Seismic Amplitude Processing:**\n",
    "    *   A bandpass filter (e.g., 5-60 Hz) is applied to each trace to remove noise outside the typical seismic frequency band. [This is a standard geophysical processing step; specific citation from the list is difficult. Many papers like Babikir et al. (2024) would implicitly use such processing before attribute analysis or ML.]\n",
    "    *   The Hilbert transform is used to compute the instantaneous amplitude (envelope) of the filtered trace, enhancing reflection strength information. [Also a standard geophysical processing step; papers like Han et al. (2024) focusing on multi-attribute learning might utilize envelope, but a direct citation for the transform itself from this list is challenging.]\n",
    "    *   The resulting envelope volume is normalized (e.g., clipping extreme percentiles and standard scaling) to stabilize model training.\n",
    "3.  **Horizon Mapping:**\n",
    "    *   Horizon `.xyt` files are loaded using `pandas`.\n",
    "    *   A KD-Tree built from the seismic trace coordinates is used to efficiently map each horizon pick (X, Y) to the nearest seismic trace (inline, crossline).\n",
    "    *   The horizon pick time (TWT) is converted to a sample index using linear interpolation based on the seismic trace\\\\s sample times.\n",
    "    *   The mapped sample indices for all horizons are stored in a 3D stack (`horizon_stack`) indexed by (horizon_index, inline_index, crossline_index).\n",
    "4.  **Patch/Trace Extraction and Labeling:**\n",
    "    *   **For CNN:** 3D patches (e.g., 32x32x32 samples) are extracted from the processed amplitude volume with a defined stride.\n",
    "    *   **For BiLSTM:** 1D traces (vertical sequences of amplitude values) are extracted at various inline/crossline locations.\n",
    "    *   **Labeling:** For both patches and traces, the label is determined by the geological interval the patch center (or trace location) falls into, based on the `horizon_stack`. The sample index of the patch center (or each sample along the trace for sequence labeling, though patch-center labeling is simpler here) is compared to the sorted horizon depths at that inline/crossline location using `np.searchsorted`. This assigns an integer label (0 to N, where N is the number of horizons) representing the facies.\n",
    "5.  **Train/Validation Split:**\n",
    "    *   The extracted, labeled data (patches for CNN, traces for BiLSTM) is split into training (80%) and validation (20%) sets.\n",
    "    *   **Stratification:** The split is stratified based on the facies labels (`y`) to ensure that the proportion of each class is approximately maintained in both the training and validation sets. This is crucial for handling potentially imbalanced datasets.\n",
    "    *   **Assumption:** We assume the data points (patches/traces) are sufficiently independent for a random split. No explicit spatial partitioning (e.g., splitting by inline/crossline ranges) is performed, which could be considered for future work to better assess spatial generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70d0dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:01:07.012002Z",
     "start_time": "2025-05-01T14:01:07.001249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Code Block 1: Imports and Initial Setup (Optimized)\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import segyio\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "import struct\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" \n",
    "\n",
    "#seed because life\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#config\n",
    "data_dir = \"F3_Demo_2020\" \n",
    "segy_path = \"F3_Demo_2020/Rawdata/Seismic_data.sgy\"\n",
    "horizon_dir = os.path.join(data_dir, \"Rawdata\", \"Surface_data\")\n",
    "horizon_files = [\n",
    "    os.path.join(horizon_dir, \"F3-Horizon-FS4.xyt.bz2\"),\n",
    "    os.path.join(horizon_dir, \"F3-Horizon-MFS4.xyt\"),\n",
    "    os.path.join(horizon_dir, \"F3-Horizon-FS6.xyt\"),\n",
    "    os.path.join(horizon_dir, \"F3-Horizon-FS7.xyt\"),\n",
    "    os.path.join(horizon_dir, \"F3-Horizon-FS8.xyt\"),\n",
    "    os.path.join(horizon_dir, \"F3-Horizon-Shallow.xyt\"),\n",
    "    os.path.join(horizon_dir, \"F3-Horizon-Top-Foresets.xyt\")\n",
    "]\n",
    "\n",
    "PATCH_SIZE = 32\n",
    "STRIDE = 16 \n",
    "MAX_PATCHES = 50000\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS_CNN = 25\n",
    "NUM_EPOCHS_BILSTM = 40\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#helpers\n",
    "def bandpass_filter(trace, lowcut=5, highcut=60, fs=250, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    # Check if trace is constant\n",
    "    if np.all(trace == trace[0]):\n",
    "        return trace # Return constant trace as is\n",
    "    # Check for NaN/inf\n",
    "    if np.isnan(trace).any() or np.isinf(trace).any():\n",
    "        return np.zeros_like(trace) # Return zeros if invalid data\n",
    "    try:\n",
    "        b, a = butter(order, [lowcut/nyq, highcut/nyq], btype=\"band\")\n",
    "        return filtfilt(b, a, trace)\n",
    "    except ValueError as e:\n",
    "        # Handle potential issues with short traces or edge cases\n",
    "        print(f\"Warning: Filtering failed for a trace - {e}. Returning zeros.\")\n",
    "        return np.zeros_like(trace)\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008b8e8-ab36-45e2-a2a8-cf9371ac9a4e",
   "metadata": {},
   "source": [
    "## Methodology: Detailed Approach\n",
    "\n",
    "This section should provide a comprehensive overview of the methods employed. While the core model architectures are defined in the code cells, this markdown section should elaborate on their design choices, the data preprocessing pipeline, and the training and evaluation strategy.\n",
    "\n",
    "### Data Preprocessing and Feature Engineering\n",
    "\n",
    "\n",
    "*   **Data Loading:** Describe the source of the F3 block data and the horizon labels.\n",
    "*   **SEG-Y Data Parsing:** Mention the extraction of seismic amplitudes and relevant metadata (e.g., inline, crossline, time/depth samples).\n",
    "*   **Horizon Mapping:** Explain how horizon data (.txt files) are used to label the seismic data, including any scaling or coordinate transformation steps.\n",
    "*   **Patch Extraction:** Detail the process of extracting 3D patches (e.g., 64x64x64 voxels) around labeled points for the CNN and corresponding 1D traces (e.g., center trace of 64 samples) for the BiLSTM. Justify the patch/trace dimensions.\n",
    "*   **Normalization:** Describe the normalization technique applied to the seismic amplitudes (e.g., per-patch or global mean/std normalization) and its importance.\n",
    "*   **Train/Validation/Test Split:** Explain the strategy for splitting the data, ensuring that the splits are representative and prevent data leakage (e.g., splitting by seismic lines if spatial correlation is a concern, or random split if appropriate).\n",
    "\n",
    "### Model Architectures\n",
    "\n",
    "**1. 3D Convolutional Neural Network (CNN) for Seismic Facies Classification:**\n",
    "\n",
    "*   **Rationale:** Explain why 3D CNNs are suitable for volumetric seismic data, highlighting their ability to learn spatial hierarchies of features directly from the 3D patches.\n",
    "*   **Architecture Details:** Describe the layers of your `SeismicCNN3D` model:\n",
    "    *   Convolutional Layers: Specify the number of layers, filter sizes (e.g., 3x3x3), number of filters, activation functions (e.g., ReLU), and any use of padding.\n",
    "    *   Pooling Layers: Detail the type of pooling (e.g., MaxPooling3D), pool size, and stride.\n",
    "    *   Batch Normalization/Dropout: Mention if and where these regularization techniques are used and their purpose (e.g., Batch Normalization after convolutions, Dropout before fully connected layers).\n",
    "    *   Flattening Layer: How the 3D feature maps are converted to a 1D vector.\n",
    "    *   Fully Connected (Dense) Layers: Specify the number of dense layers, number of units, and activation functions leading to the output layer.\n",
    "    *   Output Layer: Activation function (e.g., Softmax for multi-class classification) and number of units (corresponding to the number of seismic facies).\n",
    "\n",
    "**2. Bidirectional Long Short-Term Memory (BiLSTM) Network for Seismic Trace Analysis:**\n",
    "\n",
    "*   **Rationale:** Explain the choice of BiLSTMs for analyzing 1D seismic traces, emphasizing their ability to capture sequential dependencies and contextual information from both past and future samples in the trace.\n",
    "*   **Architecture Details:** Describe the layers of your `SeismicBiLSTM` model:\n",
    "    *   LSTM Layers: Specify the number of BiLSTM layers, hidden units per LSTM, and whether `batch_first=True` is used.\n",
    "    *   Dropout: Mention if dropout is applied within or after the LSTM layers for regularization.\n",
    "    *   Fully Connected Layers: Detail any dense layers following the LSTM output, their units, and activation functions.\n",
    "    *   Output Layer: Activation function (e.g., Softmax) and number of units.\n",
    "\n",
    "**3. Hybrid CNN-BiLSTM Model:**\n",
    "\n",
    "*   **Rationale:** Explain the motivation for combining the CNN and BiLSTM models. The hybrid approach aims to leverage the CNN's strength in capturing 3D spatial context from patches and the BiLSTM's proficiency in understanding 1D sequential patterns within individual traces. The hypothesis is that combining these complementary features will lead to a more robust and accurate classification.\n",
    "*   **Feature Fusion Strategy:** Describe how features from the CNN and BiLSTM are combined:\n",
    "    *   Feature Extraction: Explain that the pre-final layers of the trained (or partially trained) CNN and BiLSTM models are used as feature extractors.\n",
    "    *   Concatenation: The feature vectors from both models are concatenated.\n",
    "    *   Classification Head: The concatenated feature vector is then fed into one or more new fully connected layers that form the classification head of the hybrid model, culminating in a Softmax output layer.\n",
    "*   **Input to Hybrid Model:** Clarify that the `HybridSeismicDataset` provides both the 3D patch (for the CNN part) and the corresponding 1D trace (for the BiLSTM part) for each sample.\n",
    "\n",
    "### Training Strategy\n",
    "\n",
    "*   **Loss Function:** Specify the loss function used (e.g., Cross-Entropy Loss for multi-class classification).\n",
    "*   **Optimizer:** Name the optimizer (e.g., Adam, SGD) and its key hyperparameters (e.g., learning rate, weight decay).\n",
    "*   **Learning Rate Scheduling:** Mention if any learning rate scheduler (e.g., StepLR, ReduceLROnPlateau) was used and its parameters.\n",
    "*   **Batch Size:** State the batch size used for training.\n",
    "*   **Number of Epochs:** Specify the total number of training epochs.\n",
    "*   **Early Stopping:** If used, describe the criteria for early stopping (e.g., monitoring validation loss or accuracy with a certain patience).\n",
    "*   **Model Saving:** Explain that the model with the best validation performance (e.g., highest accuracy or lowest loss) is saved during training.\n",
    "*   **Hardware/Software:** Briefly mention the computational environment (e.g., GPU type if used, PyTorch version).\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "Clearly list and define the metrics used to evaluate model performance:\n",
    "*   Accuracy\n",
    "*   Precision (specify if micro, macro, or weighted average is reported, and why)\n",
    "*   Recall (specify if micro, macro, or weighted average is reported, and why)\n",
    "*   F1-Score (specify if micro, macro, or weighted average is reported, and why)\n",
    "*   Confusion Matrix: Explain its utility in understanding class-wise performance and misclassifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db67fad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:03:52.491414Z",
     "start_time": "2025-05-01T14:01:07.049809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking horizon file paths…\n",
      "  F3_Demo_2020/Rawdata/Surface_data/F3-Horizon-FS4.xyt.bz2 → FOUND\n",
      "  F3_Demo_2020/Rawdata/Surface_data/F3-Horizon-MFS4.xyt → FOUND\n",
      "  F3_Demo_2020/Rawdata/Surface_data/F3-Horizon-FS6.xyt → FOUND\n",
      "  F3_Demo_2020/Rawdata/Surface_data/F3-Horizon-FS7.xyt → FOUND\n",
      "  F3_Demo_2020/Rawdata/Surface_data/F3-Horizon-FS8.xyt → FOUND\n",
      "  F3_Demo_2020/Rawdata/Surface_data/F3-Horizon-Shallow.xyt → FOUND\n",
      "  F3_Demo_2020/Rawdata/Surface_data/F3-Horizon-Top-Foresets.xyt → FOUND\n",
      "Loading SEG-Y data...\n",
      "  Sample rate: 4.0 ms, Freq: 250.0 Hz\n",
      "  Raw CDP X range: 6054167.000–6295763.000, Raw CDP Y range: 60735564.000–60904632.000\n",
      "  Warning: Irregular inline/xline distribution detected.\n",
      "  Volume dims (IL, XL, Samples): 651, 951, 462\n",
      "  Coordinate scalar found: 4000\n",
      "  Scaled CDP X range: 24216668000.000–25183052000.000, Scaled CDP Y range: 242942256000.000–243618528000.000\n",
      "Processing amplitudes…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a176f333d800468d902b684d47ffadb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Inlines:   0%|          | 0/651 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Normalized stats (mean/std): 2326.829/1714.808\n",
      "Building KD-Tree on raw SEG-Y coordinates...\n",
      "Loading and mapping horizons…\n",
      "  Applying scale factor (10.0) to coordinates from F3-Horizon-FS4.xyt.bz2\n",
      "  F3-Horizon-FS4.xyt.bz2: 95.71% coverage (592541 points mapped)\n",
      "  Applying scale factor (10.0) to coordinates from F3-Horizon-MFS4.xyt\n",
      "  F3-Horizon-MFS4.xyt: 95.65% coverage (592177 points mapped)\n",
      "  Applying scale factor (10.0) to coordinates from F3-Horizon-FS6.xyt\n",
      "  F3-Horizon-FS6.xyt: 49.04% coverage (303622 points mapped)\n",
      "  Applying scale factor (10.0) to coordinates from F3-Horizon-FS7.xyt\n",
      "  F3-Horizon-FS7.xyt: 95.31% coverage (590096 points mapped)\n",
      "  Applying scale factor (10.0) to coordinates from F3-Horizon-FS8.xyt\n",
      "  F3-Horizon-FS8.xyt: 95.50% coverage (591259 points mapped)\n",
      "  Applying scale factor (10.0) to coordinates from F3-Horizon-Shallow.xyt\n",
      "  F3-Horizon-Shallow.xyt: 95.33% coverage (590203 points mapped)\n",
      "  Applying scale factor (10.0) to coordinates from F3-Horizon-Top-Foresets.xyt\n",
      "  F3-Horizon-Top-Foresets.xyt: 73.81% coverage (456943 points mapped)\n",
      "Extracting patches and labels…\n",
      "  Extracted 50000 patches.\n",
      "Final shapes → X: (50000, 1, 32, 32, 32), y: (50000,), classes: 8 (mapped from [0 1 2 3 4 5 6 7])\n",
      "\n",
      "Preprocessing complete (with coordinate fix).\n",
      "X shape: (50000, 1, 32, 32, 32)\n",
      "y shape: (50000,)\n",
      "Number of classes: 8\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 1e-8\n",
    "DEFAULT_LOWCUT = 5\n",
    "DEFAULT_HIGHCUT = 60\n",
    "DEFAULT_FILTER_ORDER = 4\n",
    "\n",
    "#coordinate Scaling Factor\n",
    "#Based on debug output comparison:\n",
    "#horizon x/y 1/10th of SEG-Y Raw CDP X/Y so factor up\n",
    "HORIZON_COORD_SCALE_FACTOR = 10.0\n",
    "\n",
    "def bandpass_filter(trace, lowcut=DEFAULT_LOWCUT, highcut=DEFAULT_HIGHCUT, fs=250, order=DEFAULT_FILTER_ORDER):\n",
    "    \"\"\"Applies a bandpass filter to a single trace.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    if np.all(trace == trace[0]):\n",
    "        return trace\n",
    "    if np.isnan(trace).any() or np.isinf(trace).any():\n",
    "        print(\"Warning: NaN or Inf found in trace, returning zeros.\")\n",
    "        return np.zeros_like(trace)\n",
    "    if lowcut <= 0 or highcut >= nyq:\n",
    "        print(f\"Warning: Invalid frequency cuts ({lowcut}, {highcut}) for Nyquist {nyq}. Returning zeros.\")\n",
    "        return np.zeros_like(trace)\n",
    "    try:\n",
    "        b, a = butter(order, [lowcut / nyq, highcut / nyq], btype=\"band\")\n",
    "        return filtfilt(b, a, trace)\n",
    "    except ValueError as e:\n",
    "        print(f\"Warning: Filtering failed for a trace - {e}. Returning zeros.\")\n",
    "        return np.zeros_like(trace)\n",
    "\n",
    "def load_and_preprocess_data(segy_path, horizon_files, patch_size, stride, max_patches):\n",
    "    #Loads SEG-Y data and horizon picks (X,Y,time), processes amplitudes,\n",
    "    #extracts 3D patches, and returns X (N,1,D,H,W), y (N,), num_classes.\n",
    "    \n",
    "    if not os.path.exists(segy_path):\n",
    "        raise FileNotFoundError(f\"SEG-Y file not found: {segy_path}\")\n",
    "    print(\"Checking horizon file paths…\")\n",
    "    valid_horizons = []\n",
    "    for hf in horizon_files:\n",
    "        if os.path.exists(hf):\n",
    "            print(f\"  {hf} → FOUND\")\n",
    "            valid_horizons.append(hf)\n",
    "        else:\n",
    "            print(f\"  {hf} → MISSING\")\n",
    "    if not valid_horizons:\n",
    "        raise ValueError(f\"No valid horizon files found; checked: {horizon_files}\")\n",
    "\n",
    "    #read SEG-Y volume\n",
    "    print(\"Loading SEG-Y data...\")\n",
    "    try:\n",
    "        with segyio.open(segy_path, \"r\", ignore_geometry=True) as f:\n",
    "            f.mmap()\n",
    "            inlines = f.attributes(segyio.TraceField.INLINE_3D)[:]\n",
    "            xlines = f.attributes(segyio.TraceField.CROSSLINE_3D)[:]\n",
    "            raw_cdpX = f.attributes(segyio.TraceField.CDP_X)[:].astype(float)\n",
    "            raw_cdpY = f.attributes(segyio.TraceField.CDP_Y)[:].astype(float)\n",
    "            samples = np.array(f.samples)\n",
    "            sample_rate = segyio.tools.dt(f) / 1000.0\n",
    "            fs = 1000.0 / sample_rate\n",
    "\n",
    "            print(f\"  Sample rate: {sample_rate} ms, Freq: {fs:.1f} Hz\")\n",
    "            print(f\"  Raw CDP X range: {raw_cdpX.min():.3f}–{raw_cdpX.max():.3f}, \"\n",
    "                  f\"Raw CDP Y range: {raw_cdpY.min():.3f}–{raw_cdpY.max():.3f}\")\n",
    "\n",
    "            uni_il, il_counts = np.unique(inlines, return_counts=True)\n",
    "            uni_xl, xl_counts = np.unique(xlines, return_counts=True)\n",
    "            if not (il_counts.size > 0 and xl_counts.size > 0 and\n",
    "                    np.all(il_counts == il_counts[0]) and np.all(xl_counts == xl_counts[0])):\n",
    "                print(\"  Warning: Irregular inline/xline distribution detected.\")\n",
    "            else:\n",
    "                 print(f\"  Grid appears regular: {il_counts[0]} traces per inline, {xl_counts[0]} traces per xline.\")\n",
    "\n",
    "            n_ilines, n_xlines, n_samples = len(uni_il), len(uni_xl), len(samples)\n",
    "            print(f\"  Volume dims (IL, XL, Samples): {n_ilines}, {n_xlines}, {n_samples}\")\n",
    "\n",
    "            with open(segy_path, \"rb\") as raw_file:\n",
    "                raw_file.seek(3216)\n",
    "                scalar_bytes = raw_file.read(2)\n",
    "                if len(scalar_bytes) == 2:\n",
    "                    scalar = struct.unpack(\">h\", scalar_bytes)[0]\n",
    "                    print(f\"  Coordinate scalar found: {scalar}\")\n",
    "                else:\n",
    "                    scalar = 1\n",
    "                    print(\"  Warning: Could not read coordinate scalar, assuming 1.\")\n",
    "\n",
    "            #ppply scalar for info purposes, but KDTree uses raw\n",
    "            if scalar != 1:\n",
    "                scaled_cdpX = raw_cdpX.copy()\n",
    "                scaled_cdpY = raw_cdpY.copy()\n",
    "                if scalar > 0:\n",
    "                    scaled_cdpX *= scalar\n",
    "                    scaled_cdpY *= scalar\n",
    "                elif scalar < 0:\n",
    "                    scaled_cdpX /= abs(scalar)\n",
    "                    scaled_cdpY /= abs(scalar)\n",
    "                print(f\"  Scaled CDP X range: {scaled_cdpX.min():.3f}–{scaled_cdpX.max():.3f}, \"\n",
    "                      f\"Scaled CDP Y range: {scaled_cdpY.min():.3f}–{scaled_cdpY.max():.3f}\")\n",
    "\n",
    "            print(\"Processing amplitudes…\")\n",
    "            volume = np.zeros((n_ilines, n_xlines, n_samples), dtype=np.float32)\n",
    "            trace_map = {}\n",
    "            for i in range(f.tracecount):\n",
    "                trace_map[(inlines[i], xlines[i])] = i\n",
    "\n",
    "            for il_idx, il_val in enumerate(tqdm(uni_il, desc=\"    Inlines\")):\n",
    "                for xl_idx, xl_val in enumerate(uni_xl):\n",
    "                    trace_index = trace_map.get((il_val, xl_val))\n",
    "                    if trace_index is not None:\n",
    "                        trace = f.trace.raw[trace_index].astype(np.float32)\n",
    "                        filtered_trace = bandpass_filter(trace, fs=fs)\n",
    "                        env = np.abs(hilbert(filtered_trace))\n",
    "                        volume[il_idx, xl_idx, :] = env\n",
    "\n",
    "            mask = volume != 0\n",
    "            mean_val, std_val = 0.0, 1.0\n",
    "            if mask.any():\n",
    "                p1, p99 = np.percentile(volume[mask], [1, 99])\n",
    "                volume = np.clip(volume, p1, p99)\n",
    "                mean_val = volume[mask].mean()\n",
    "                std_val = volume[mask].std()\n",
    "                volume[mask] = (volume[mask] - mean_val) / (std_val + EPSILON)\n",
    "            print(f\"  Normalized stats (mean/std): {mean_val:.3f}/{std_val:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing SEG-Y file: {e}\")\n",
    "        raise\n",
    "\n",
    "    print(\"Building KD-Tree on raw SEG-Y coordinates...\")\n",
    "    coords = np.column_stack((raw_cdpX, raw_cdpY))\n",
    "    try:\n",
    "        tree = cKDTree(coords)\n",
    "    except Exception as e:\n",
    "        print(f\"Error building KDTree: {e}\")\n",
    "        raise\n",
    "\n",
    "    time_to_idx = interp1d(samples, np.arange(n_samples),\n",
    "                           kind=\"nearest\", bounds_error=False, fill_value=-1)\n",
    "\n",
    "    print(\"Loading and mapping horizons…\")\n",
    "    horizon_stack = np.full((len(valid_horizons), n_ilines, n_xlines),\n",
    "                            np.nan, dtype=float)\n",
    "    il_map = {val: idx for idx, val in enumerate(uni_il)}\n",
    "    xl_map = {val: idx for idx, val in enumerate(uni_xl)}\n",
    "\n",
    "    for h_idx, hf in enumerate(valid_horizons):\n",
    "        try:\n",
    "            df = pd.read_csv(hf, sep=r'\\s+', header=None,\n",
    "                             names=[\"X\", \"Y\", \"time_ms\"], engine='python', compression='infer')\n",
    "            if df.isnull().values.any():\n",
    "                 print(f\"  Warning: NaNs detected in {os.path.basename(hf)}, dropping rows.\")\n",
    "                 df = df.dropna()\n",
    "            if df.empty:\n",
    "                print(f\"  Warning: No valid data found in {os.path.basename(hf)}\")\n",
    "                continue\n",
    "\n",
    "            #FIX: Scale horizon coordinates to match SEG-Y raw coordinates\n",
    "            print(f\"  Applying scale factor ({HORIZON_COORD_SCALE_FACTOR}) to coordinates from {os.path.basename(hf)}\")\n",
    "            df[\"X\"] *= HORIZON_COORD_SCALE_FACTOR\n",
    "            df[\"Y\"] *= HORIZON_COORD_SCALE_FACTOR\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error reading or scaling horizon file {hf}: {e}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        tops = np.full((n_ilines, n_xlines), np.nan, dtype=float)\n",
    "        mapped_points = 0\n",
    "        for Xval, Yval, t_ms in df.itertuples(index=False):\n",
    "            try:\n",
    "                dist, tidx = tree.query([Xval, Yval])\n",
    "                if tidx < 0 or tidx >= len(raw_cdpX):\n",
    "                    continue\n",
    "                il_hdr, xl_hdr = inlines[tidx], xlines[tidx]\n",
    "                i_idx = il_map.get(il_hdr)\n",
    "                x_idx = xl_map.get(xl_hdr)\n",
    "                if i_idx is None or x_idx is None:\n",
    "                    continue\n",
    "                s_idx = int(time_to_idx(t_ms))\n",
    "                if 0 <= s_idx < n_samples and np.isnan(tops[i_idx, x_idx]):\n",
    "                    tops[i_idx, x_idx] = s_idx\n",
    "                    mapped_points += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Error processing point ({Xval}, {Yval}, {t_ms}) from {os.path.basename(hf)}: {e}\")\n",
    "                continue\n",
    "\n",
    "        horizon_stack[h_idx] = tops\n",
    "        coverage = (~np.isnan(tops)).sum() / tops.size * 100 if tops.size > 0 else 0\n",
    "        print(f\"  {os.path.basename(hf)}: {coverage:.2f}% coverage ({mapped_points} points mapped)\")\n",
    "\n",
    "    if np.all(np.isnan(horizon_stack)):\n",
    "         raise ValueError(\"Horizon mapping resulted in zero coverage for all files. Check coordinate systems and file contents.\")\n",
    "\n",
    "    print(\"Extracting patches and labels…\")\n",
    "    patches, labels = [], []\n",
    "    half_patch = patch_size // 2\n",
    "    for il in range(0, n_ilines - patch_size + 1, stride):\n",
    "        for xl in range(0, n_xlines - patch_size + 1, stride):\n",
    "            ctr_il, ctr_xl = il + half_patch, xl + half_patch\n",
    "            depths_at_center = horizon_stack[:, ctr_il, ctr_xl]\n",
    "            valid_depths = np.sort(depths_at_center[~np.isnan(depths_at_center)])\n",
    "            if valid_depths.size == 0:\n",
    "                continue\n",
    "            for sm in range(0, n_samples - patch_size + 1, stride):\n",
    "                patch = volume[il : il + patch_size,\n",
    "                               xl : xl + patch_size,\n",
    "                               sm : sm + patch_size]\n",
    "                if np.isfinite(patch).all():\n",
    "                    center_depth_sample = sm + half_patch\n",
    "                    label = np.searchsorted(valid_depths, center_depth_sample, side='right')\n",
    "                    patches.append(patch[np.newaxis, ...])\n",
    "                    labels.append(label)\n",
    "                    if len(patches) >= max_patches:\n",
    "                        break\n",
    "            if len(patches) >= max_patches:\n",
    "                break\n",
    "        if len(patches) >= max_patches:\n",
    "            break\n",
    "\n",
    "    if not patches:\n",
    "        raise ValueError(\"No valid patches extracted. Check patch_size, stride, horizon coverage, and volume normalization.\")\n",
    "    print(f\"  Extracted {len(patches)} patches.\")\n",
    "\n",
    "    X = np.stack(patches).astype(np.float32)\n",
    "    y = np.array(labels, dtype=np.int64)\n",
    "    unique_labels = np.unique(y)\n",
    "    num_classes = len(unique_labels)\n",
    "    label_map = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "    y_mapped = np.vectorize(label_map.get)(y)\n",
    "\n",
    "    print(f\"Final shapes → X: {X.shape}, y: {y_mapped.shape}, classes: {num_classes} (mapped from {unique_labels})\")\n",
    "\n",
    "    return X, y_mapped, num_classes\n",
    "\n",
    "try:\n",
    "    X, y, num_classes = load_and_preprocess_data(\n",
    "        segy_path, horizon_files, PATCH_SIZE, STRIDE, MAX_PATCHES\n",
    "    )\n",
    "    print(\"\\nPreprocessing complete (with coordinate fix).\")\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    print(\"Number of classes:\", num_classes)\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during preprocessing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8737bc26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:03:54.633549Z",
     "start_time": "2025-05-01T14:03:52.554469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN DataLoaders: Train batches=1250, Val batches=313\n",
      "Extracting traces for BiLSTM...\n",
      "BiLSTM DataLoaders: Train batches=1250, Val batches=313\n",
      "Sample trace shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "#Train/Validation Split and DataLoaders\n",
    "X_train_cnn, X_val_cnn, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "#create TensorDatasets and DataLoaders for CNN\n",
    "train_ds_cnn = TensorDataset(torch.tensor(X_train_cnn, dtype=torch.float32),\n",
    "                             torch.tensor(y_train, dtype=torch.long))\n",
    "val_ds_cnn = TensorDataset(torch.tensor(X_val_cnn, dtype=torch.float32),\n",
    "                           torch.tensor(y_val, dtype=torch.long))\n",
    "train_loader_cnn = DataLoader(train_ds_cnn, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader_cnn = DataLoader(val_ds_cnn, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"CNN DataLoaders: Train batches={len(train_loader_cnn)}, Val batches={len(val_loader_cnn)}\")\n",
    "\n",
    "#Data Preparation for BiLSTM using traces\n",
    "def extract_traces_from_patches(patches, num_traces_per_patch=5):\n",
    "    N, C, D, H, W = patches.shape\n",
    "    all_traces = np.zeros((N, D), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        patch_traces = np.zeros((num_traces_per_patch, D), dtype=np.float32)\n",
    "        for j in range(num_traces_per_patch):\n",
    "            h, w = np.random.randint(0, H), np.random.randint(0, W)\n",
    "            patch_traces[j] = patches[i, 0, :, h, w]\n",
    "        all_traces[i] = np.mean(patch_traces, axis=0)\n",
    "    return all_traces\n",
    "\n",
    "print(\"Extracting traces for BiLSTM...\")\n",
    "X_train_traces = extract_traces_from_patches(X_train_cnn)\n",
    "X_val_traces = extract_traces_from_patches(X_val_cnn)\n",
    "\n",
    "#for use later\n",
    "def extract_center_trace(patch):\n",
    "    C, D, H, W = patch.shape\n",
    "    random_h = np.random.randint(0, H)\n",
    "    random_w = np.random.randint(0, W)\n",
    "    trace = patch[0, :, random_h, random_w]\n",
    "    return trace.astype(np.float32)\n",
    "\n",
    "#create TensorDatasets and DataLoaders for BiLSTM\n",
    "train_ds_bilstm = TensorDataset(torch.tensor(X_train_traces, dtype=torch.float32),\n",
    "                                torch.tensor(y_train, dtype=torch.long))\n",
    "val_ds_bilstm = TensorDataset(torch.tensor(X_val_traces, dtype=torch.float32),\n",
    "                              torch.tensor(y_val, dtype=torch.long))\n",
    "train_loader_bilstm = DataLoader(train_ds_bilstm, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader_bilstm = DataLoader(val_ds_bilstm, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"BiLSTM DataLoaders: Train batches={len(train_loader_bilstm)}, Val batches={len(val_loader_bilstm)}\")\n",
    "print(f\"Sample trace shape: {X_train_traces[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d7ffda-dba3-4d11-9c68-553bb1f926e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSeismicDataset: Initialized with 40000 samples.\n",
      "HybridSeismicDataset: Initialized with 10000 samples.\n",
      "Hybrid DataLoaders: Train batches=1250, Val batches=313\n",
      "Sample Batch Shapes -> Patch: torch.Size([32, 1, 32, 32, 32]), Trace: torch.Size([32, 32]), Label: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "#Hybrid Dataset\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class HybridSeismicDataset(Dataset):\n",
    "    def __init__(self, patches, labels):\n",
    "    #patches (numpy.ndarray): The 3D patches (N, C, D, H, W).\n",
    "    #labels (numpy.ndarray): The corresponding labels (N,).\n",
    "        #convert to tensors to avoid issues in DataLoader workers\n",
    "        self.patches = torch.tensor(patches, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        print(f\"HybridSeismicDataset: Initialized with {len(self.patches)} samples.\")\n",
    "        if len(self.patches) != len(self.labels):\n",
    "             raise ValueError(\"Patches and labels must have the same number of samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = self.patches[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        #extract the corresponding trace from the patch\n",
    "        #convert patch tensor back to numpy temporarily for extraction function\n",
    "        trace_np = extract_center_trace(patch.numpy())\n",
    "        trace = torch.tensor(trace_np, dtype=torch.float32)\n",
    "        \n",
    "        return patch, trace, label\n",
    "\n",
    "\n",
    "\n",
    "train_ds_hybrid = HybridSeismicDataset(X_train_cnn, y_train)\n",
    "val_ds_hybrid = HybridSeismicDataset(X_val_cnn, y_val)\n",
    "BATCH_SIZE_HYBRID = 32 \n",
    "train_loader_hybrid = DataLoader(train_ds_hybrid, batch_size=BATCH_SIZE_HYBRID, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader_hybrid = DataLoader(val_ds_hybrid, batch_size=BATCH_SIZE_HYBRID, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"Hybrid DataLoaders: Train batches={len(train_loader_hybrid)}, Val batches={len(val_loader_hybrid)}\")\n",
    "\n",
    "#verify\n",
    "sample_patch, sample_trace, sample_label = next(iter(train_loader_hybrid))\n",
    "print(f\"Sample Batch Shapes -> Patch: {sample_patch.shape}, Trace: {sample_trace.shape}, Label: {sample_label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fb3b0",
   "metadata": {},
   "source": [
    "### Model Architectures\n",
    "\n",
    "Two primary architectures are compared:\n",
    "\n",
    "1.  **3D Convolutional Neural Network (CNN):**\n",
    "    *   **Input:** 3D seismic amplitude patches (e.g., 1 x 32 x 32 x 32).\n",
    "    *   **Architecture:** A simple CNN with two blocks, each containing a 3D Convolution layer, Batch Normalization, ReLU activation, and Max Pooling. This is followed by a Flatten layer and a fully connected classifier head with Dropout for regularization.\n",
    "    *   **Rationale:** CNNs excel at learning spatial hierarchies of features directly from grid-like data, making them suitable for analyzing 3D seismic patches.\n",
    "\n",
    "2.  **Bidirectional Long Short-Term Memory (BiLSTM):**\n",
    "    *   **Input:** 1D seismic amplitude traces (sequences of amplitude values along the depth/time axis).\n",
    "    *   **Architecture:** A BiLSTM network processes the input sequence. LSTMs are a type of Recurrent Neural Network (RNN) specifically designed to handle long-range dependencies in sequential data. The bidirectional nature allows the model to learn from both past (earlier samples) and future (later samples) context within the trace. The output from the BiLSTM layers is then passed to a fully connected classifier head.\n",
    "    *   **Rationale:** Seismic traces represent sequences where the amplitude at one sample is related to its neighbors. LSTMs are adept at capturing such temporal/sequential dependencies, which might be relevant for distinguishing facies based on vertical reflection patterns. BiLSTMs enhance this by considering the full trace context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24112eb5-dd52-4f86-8c70-505dbfbf6dcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:03:55.517973Z",
     "start_time": "2025-05-01T14:03:54.639330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing HybridCNNBiLSTM model...\n",
      "  Detected CNN feature size (flattened): 16384\n",
      "  Detected BiLSTM feature size: 128\n",
      "  Combined feature size: 16512\n",
      "  Added combined classifier head.\n",
      "--- CNN Model ---\n",
      "SeismicCNN3D(\n",
      "  (features): Sequential(\n",
      "    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=16384, out_features=64, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "--- BiLSTM Model ---\n",
      "SeismicBiLSTM(\n",
      "  (lstm): LSTM(1, 64, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "--- Hybrid Model ---\n",
      "HybridCNNBiLSTM(\n",
      "  (cnn_features): Sequential(\n",
      "    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (bilstm): LSTM(1, 64, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=16512, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Model Definitions\n",
    "\n",
    "#Simple 3D CNN\n",
    "class SeismicCNN3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=num_classes, patch_depth=PATCH_SIZE):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv3d(in_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2), # D/2, H/2, W/2\n",
    "            # Block 2\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2) # D/4, H/4, W/4\n",
    "        )\n",
    "        #calculate flattened size dynamically based on input patch depth\n",
    "        feat_depth = patch_depth // 4\n",
    "        feat_h = PATCH_SIZE // 4 \n",
    "        feat_w = PATCH_SIZE // 4\n",
    "        flat_size = 32 * feat_depth * feat_h * feat_w\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat_size, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x shape: (N, C, D, H, W) - Ensure D is samples/depth\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "#BiLSTM Model\n",
    "class SeismicBiLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, num_classes=num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        #input size is 1 if feeding raw amplitudes, could be embedding dim if using binned values\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True, #expects (batch, seq_len, features)\n",
    "                            bidirectional=True,\n",
    "                            dropout=dropout if num_layers > 1 else 0)\n",
    "        #classifier input features: hidden_size * 2 (bidirectional)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #input x shape: (batch, seq_len) need (batch, seq_len, features=1)\n",
    "        if x.ndim == 2:\n",
    "            x = x.unsqueeze(-1)\n",
    "\n",
    "        #LSTM returns output, (h_n, c_n)\n",
    "        #output shape: (batch, seq_len, hidden_size * 2)\n",
    "        #h_n shape: (num_layers * 2, batch, hidden_size)\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "\n",
    "        #use the output of the last time step for classification\n",
    "        #could use hidden state or pooling over sequence\n",
    "        last_step_output = lstm_out[:, -1, :] #shape: (batch, hidden_size * 2)\n",
    "\n",
    "        logits = self.classifier(last_step_output)\n",
    "        return logits\n",
    "\n",
    "cnn_model = SeismicCNN3D(num_classes=num_classes, patch_depth=X.shape[2]).to(device)\n",
    "bilstm_model = SeismicBiLSTM(input_size=1, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=1e-4)\n",
    "optimizer_bilstm = optim.Adam(bilstm_model.parameters(), lr=1e-3)\n",
    "\n",
    "class HybridCNNBiLSTM(nn.Module):\n",
    "    def __init__(self, cnn_model, bilstm_model, num_classes):\n",
    "        super().__init__()\n",
    "        print(\"Initializing HybridCNNBiLSTM model...\")\n",
    "        \n",
    "        #CNN Branch\n",
    "        self.cnn_features = cnn_model.features\n",
    "        try:\n",
    "            cnn_flat_size = cnn_model.classifier[1].in_features\n",
    "            print(f\"  Detected CNN feature size (flattened): {cnn_flat_size}\")\n",
    "        except (AttributeError, IndexError):\n",
    "             # Fallback calculation if structure differs (use with caution)\n",
    "             print(\"  Warning: Could not automatically detect CNN feature size. Calculating fallback...\")\n",
    "\n",
    "        #BiLSTM Branch\n",
    "        #ue the LSTM part of the provided BiLSTM model\n",
    "        self.bilstm = bilstm_model.lstm\n",
    "        bilstm_feature_size = bilstm_model.lstm.hidden_size * 2\n",
    "        print(f\"  Detected BiLSTM feature size: {bilstm_feature_size}\")\n",
    "\n",
    "        #combined Classifier Head\n",
    "        combined_feature_size = cnn_flat_size + bilstm_feature_size\n",
    "        print(f\"  Combined feature size: {combined_feature_size}\")\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(combined_feature_size, 128), # Intermediate layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        print(f\"  Added combined classifier head.\")\n",
    "\n",
    "        #otional,Freeze the original model parts\n",
    "        #for param in self.cnn_features.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        #for param in self.bilstm.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        #print(\"  Note: CNN and BiLSTM feature extractors frozen.\") \n",
    "\n",
    "    def forward(self, patch, trace):\n",
    "        #patch shape: (N, C, D, H, W)\n",
    "        #trace shape: (N, SeqLen) or (N, SeqLen, 1)\n",
    "        \n",
    "        # Process\n",
    "        cnn_out = self.cnn_features(patch)\n",
    "        cnn_out_flat = torch.flatten(cnn_out, 1) # Flatten starting from dim 1\n",
    "        if trace.ndim == 2:\n",
    "            trace = trace.unsqueeze(-1) # (N, SeqLen) -> (N, SeqLen, 1)\n",
    "        lstm_out, (hidden, cell) = self.bilstm(trace)\n",
    "        # Use the output of the last time step\n",
    "        bilstm_out = lstm_out[:, -1, :] # Shape: (N, hidden_size * 2)\n",
    "        combined_features = torch.cat((cnn_out_flat, bilstm_out), dim=1)\n",
    "        #classify\n",
    "        logits = self.classifier(combined_features)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "hybrid_model = HybridCNNBiLSTM(cnn_model, bilstm_model, num_classes).to(device)\n",
    "\n",
    "print(\"--- CNN Model ---\")\n",
    "print(cnn_model)\n",
    "print(\"--- BiLSTM Model ---\")\n",
    "print(bilstm_model)\n",
    "print(\"--- Hybrid Model ---\")\n",
    "print(hybrid_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9727f10-5186-4542-a3fb-627c1fe9c322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:03:55.517973Z",
     "start_time": "2025-05-01T14:03:54.639330Z"
    }
   },
   "source": [
    "### Training Procedure\n",
    "\n",
    "Both models are trained using the Adam optimizer and CrossEntropyLoss function. Standard training loops are employed, iterating through the training data in batches for a fixed number of epochs. After each epoch, the models are evaluated on the validation set to monitor performance and prevent overfitting. Training and validation loss and accuracy are recorded for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf0f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:10:32.305126Z",
     "start_time": "2025-05-01T14:10:29.814458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training CNN for 25 epochs ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/25 [Train]:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/25 [Val]:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train Loss: 1.1232, Acc: 0.5917 | Val Loss: 0.8138, Acc: 0.7080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/25 [Train]:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/25 [Val]:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 - Train Loss: 0.8905, Acc: 0.6601 | Val Loss: 0.7082, Acc: 0.7167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/25 [Train]:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/25 [Val]:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 - Train Loss: 0.8021, Acc: 0.6900 | Val Loss: 0.6365, Acc: 0.7592\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf876b7af4147da864388ea50cabcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/25 [Train]:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training and Eval Loop\n",
    "\n",
    "#debug step\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#same issue with device about not supporting 3d on mps\n",
    "def train_evaluate_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, model_name=\"Model\"):\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "\n",
    "    print(f\"\\n--- Training {model_name} for {num_epochs} epochs ---\")\n",
    "    for epoch in range(num_epochs):\n",
    "        #train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "\n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            train_pbar.set_postfix({\"Loss\": running_loss / total_train, \"Acc\": correct_train / total_train})\n",
    "\n",
    "        epoch_train_loss = running_loss / total_train\n",
    "        epoch_train_acc = correct_train / total_train\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "        train_acc_history.append(epoch_train_acc)\n",
    "\n",
    "        #val\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val, total_val = 0, 0\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                val_pbar.set_postfix({\"Loss\": running_val_loss / total_val, \"Acc\": correct_val / total_val})\n",
    "\n",
    "        epoch_val_loss = running_val_loss / total_val\n",
    "        epoch_val_acc = correct_val / total_val\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "        val_acc_history.append(epoch_val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.4f} | Val Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    print(f\"Finished training {model_name}.\")\n",
    "    history = {\n",
    "        \"train_loss\": train_loss_history, \"val_loss\": val_loss_history,\n",
    "        \"train_acc\": train_acc_history, \"val_acc\": val_acc_history\n",
    "    }\n",
    "    return model, history\n",
    "\n",
    "#train\n",
    "cnn_model, cnn_history = train_evaluate_model(cnn_model, train_loader_cnn, val_loader_cnn,\n",
    "                                            criterion, optimizer_cnn, device, NUM_EPOCHS_CNN, \"CNN\")\n",
    "bilstm_model, bilstm_history = train_evaluate_model(bilstm_model, train_loader_bilstm, val_loader_bilstm,criterion, optimizer_bilstm, device, NUM_EPOCHS_BILSTM, \"BiLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8e144-34c4-4add-8b98-57428e080546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hybrid_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    print(f\"Starting hybrid training for {num_epochs} epochs on {device}...\")\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "                print(\"Training Phase:\")\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "                print(\"Validation Phase:\")\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            progress_bar = tqdm(dataloader, desc=f\"{phase.capitalize()} Epoch {epoch+1}\", leave=False)\n",
    "            # Modified loop to unpack three items: patch, trace, label\n",
    "            for patches, traces, labels in progress_bar:\n",
    "                patches = patches.to(device)\n",
    "                traces = traces.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    # Pass both inputs to the hybrid model\n",
    "                    outputs = model(patches, traces)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                batch_loss = loss.item() * patches.size(0)\n",
    "                batch_corrects = torch.sum(preds == labels.data)\n",
    "                running_loss += batch_loss\n",
    "                running_corrects += batch_corrects\n",
    "                total_samples += patches.size(0)\n",
    "\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{batch_loss/patches.size(0):.4f}\",\n",
    "                    'acc': f\"{batch_corrects.double()/patches.size(0):.4f}\"\n",
    "                })\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "            epoch_acc = running_corrects.double() / total_samples\n",
    "\n",
    "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == \"train\":\n",
    "                history[\"train_loss\"].append(epoch_loss)\n",
    "                history[\"train_acc\"].append(epoch_acc.item())\n",
    "            else:\n",
    "                history[\"val_loss\"].append(epoch_loss)\n",
    "                history[\"val_acc\"].append(epoch_acc.item())\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    print(f\"  New best validation accuracy: {best_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\nTraining complete. Best validation Acc: {best_acc:4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "def evaluate_hybrid_model(model, dataloader, criterion, device):\n",
    "    print(f\"Evaluating hybrid model on {device}...\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Evaluation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for patches, traces, labels in progress_bar:\n",
    "            patches = patches.to(device)\n",
    "            traces = traces.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(patches, traces)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_loss += loss.item() * patches.size(0)\n",
    "            total_samples += patches.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'acc': f\"{torch.sum(preds == labels.data).double()/patches.size(0):.4f}\"\n",
    "            })\n",
    "\n",
    "    avg_loss = running_loss / total_samples\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    print(f\"Evaluation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Evaluation Precision (Weighted): {precision:.4f}\")\n",
    "    print(f\"Evaluation Recall (Weighted): {recall:.4f}\")\n",
    "    print(f\"Evaluation F1-Score (Weighted): {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    return avg_loss, accuracy, precision, recall, f1, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Function and Execution\n",
    "def evaluate_final_model(model, dataloader, device, model_name=\"Model\"):\n",
    "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=f\"Evaluating {model_name}\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
    "    report = classification_report(all_labels, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"{model_name} Validation Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    results = {\n",
    "        \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1,\n",
    "        \"report\": report, \"confusion_matrix\": cm\n",
    "    }\n",
    "    return results\n",
    "#eval\n",
    "cnn_results = evaluate_final_model(cnn_model, val_loader_cnn, device, \"CNN\")\n",
    "bilstm_results = evaluate_final_model(bilstm_model, val_loader_bilstm, device, \"BiLSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5f87f-911c-47be-946c-3e4ce9145935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Hybrid Datasets and DataLoaders\n",
    "train_loader_hybrid = DataLoader(train_ds_hybrid, batch_size=BATCH_SIZE_HYBRID, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader_hybrid = DataLoader(val_ds_hybrid, batch_size=BATCH_SIZE_HYBRID, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f\"Hybrid DataLoaders: Train batches={len(train_loader_hybrid)}, Val batches={len(val_loader_hybrid)}\")\n",
    "\n",
    "print(\"Instantiating Hybrid Model...\")\n",
    "#pass  cnn_model and bilstm_model instances\n",
    "hybrid_model = HybridCNNBiLSTM(cnn_model.to(device), bilstm_model.to(device), num_classes).to(device)\n",
    "print(hybrid_model)\n",
    "\n",
    "#define loss and optimizer\n",
    "LEARNING_RATE_HYBRID = 1e-4 # Adjust as needed\n",
    "NUM_EPOCHS_HYBRID = 5     # Adjust as needed\n",
    "\n",
    "criterion_hybrid = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimize all parameters in the hybrid model (including CNN/BiLSTM parts)\n",
    "optimizer_hybrid = optim.Adam(hybrid_model.parameters(), lr=LEARNING_RATE_HYBRID)\n",
    "print(\"Optimizer set to train all parameters of the hybrid model.\")\n",
    "\n",
    "#train\n",
    "hybrid_model, history_hybrid = train_hybrid_model(\n",
    "    hybrid_model,\n",
    "    train_loader_hybrid,\n",
    "    val_loader_hybrid,\n",
    "    criterion_hybrid,\n",
    "    optimizer_hybrid,\n",
    "    num_epochs=NUM_EPOCHS_HYBRID,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "#eval\n",
    "print(\"\\n--- Evaluating Best Hybrid Model ---\")\n",
    "val_loss_hybrid, val_acc_hybrid, prec_hybrid, recall_hybrid, f1_hybrid, conf_matrix_hybrid = evaluate_hybrid_model(hybrid_model, val_loader_hybrid, criterion_hybrid, device )\n",
    "hybrid_results = { \"accuracy\": val_acc_hybrid, \"precision\": prec_hybrid, \"recall\": recall_hybrid, \"f1\": f1_hybrid, \"confusion_matrix\": conf_matrix_hybrid} \n",
    "print(\"Hybrid model evaluation results stored.\") \n",
    "all_results = {\"CNN\": cnn_results, \"BiLSTM\": bilstm_results, \"Hybrid\": hybrid_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda56ab",
   "metadata": {},
   "source": [
    "## Results and Analysis\n",
    "\n",
    "We evaluate the trained CNN and BiLSTM models on the held-out validation set using standard classification metrics: accuracy, precision, recall, and F1-score (weighted average), along with confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a4c90-f1d8-4ea3-a8a6-8303ee61d814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plots\n",
    "def plot_training_history(history, model_name):\n",
    "    if not history or not isinstance(history, dict) or not all(k in history for k in [\"train_loss\", \"val_loss\", \"train_acc\", \"val_acc\"]):\n",
    "        print(f\"Warning: Invalid or incomplete history data for {model_name}. Skipping history plot.\")\n",
    "        return\n",
    "        \n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history[\"train_loss\"], \"bo-\", label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], \"ro-\", label=\"Val Loss\")\n",
    "    plt.title(f\"{model_name} Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history[\"train_acc\"], \"bo-\", label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], \"ro-\", label=\"Val Accuracy\")\n",
    "    plt.title(f\"{model_name} Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Plotting Training Histories...\")\n",
    "if \"cnn_history\" in locals():\n",
    "    plot_training_history(cnn_history, \"CNN\")\n",
    "else:\n",
    "    print(\"Skipping CNN history plot (cnn_history not found).\")\n",
    "    \n",
    "if \"bilstm_history\" in locals():\n",
    "    plot_training_history(bilstm_history, \"BiLSTM\")\n",
    "else:\n",
    "    print(\"Skipping BiLSTM history plot (bilstm_history not found).\")\n",
    "\n",
    "if \"history_hybrid\" in locals():\n",
    "    plot_training_history(history_hybrid, \"Hybrid\")\n",
    "else:\n",
    "    print(\"Skipping Hybrid history plot (history_hybrid not found).\")\n",
    "\n",
    "print(\"\\nPlotting Performance Comparison...\")\n",
    "if \"all_results\" not in locals() or not isinstance(all_results, dict):\n",
    "    print(\"Error: `all_results` dictionary not found or invalid. Cannot create comparison plot.\")\n",
    "else:\n",
    "    metrics_to_plot = [\"accuracy\", \"precision\", \"recall\", \"f1\"] # Use lowercase keys as likely stored from evaluate function\n",
    "    model_names = list(all_results.keys()) # Should include \"CNN\", \"BiLSTM\", \"Hybrid\"\n",
    "    num_models = len(model_names)\n",
    "    num_metrics = len(metrics_to_plot)\n",
    "    \n",
    "    # Check if all models and metrics exist\n",
    "    valid_plot = True\n",
    "    for model in model_names:\n",
    "        if model not in all_results:\n",
    "             print(f\"Warning: Model \t'{model}\t' not found in all_results. Skipping comparison plot.\")\n",
    "             valid_plot = False\n",
    "             break\n",
    "        for metric in metrics_to_plot:\n",
    "             if metric not in all_results[model]:\n",
    "                 print(f\"Warning: Metric \t'{metric}\t' not found for model \t'{model}\t' in all_results. Skipping comparison plot.\")\n",
    "                 valid_plot = False\n",
    "                 break\n",
    "        if not valid_plot: break\n",
    "\n",
    "    if valid_plot:\n",
    "        x = np.arange(num_metrics)\n",
    "        width = 0.25 \n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        offset_cnn = -width\n",
    "        offset_bilstm = 0\n",
    "        offset_hybrid = width\n",
    "        \n",
    "        cnn_metrics = [all_results.get(\"CNN\", {}).get(metric, 0) for metric in metrics_to_plot]\n",
    "        bilstm_metrics = [all_results.get(\"BiLSTM\", {}).get(metric, 0) for metric in metrics_to_plot]\n",
    "        hybrid_metrics = [all_results.get(\"Hybrid\", {}).get(metric, 0) for metric in metrics_to_plot]\n",
    "\n",
    "        rects1 = ax.bar(x + offset_cnn, cnn_metrics, width, label=\"CNN\")\n",
    "        rects2 = ax.bar(x + offset_bilstm, bilstm_metrics, width, label=\"BiLSTM\")\n",
    "        rects3 = ax.bar(x + offset_hybrid, hybrid_metrics, width, label=\"Hybrid\") \n",
    "\n",
    "        ax.set_ylabel(\"Score\")\n",
    "        ax.set_title(\"Model Performance Comparison (Validation Set)\")\n",
    "        ax.set_xticks(x) # Keep ticks centered between the groups\n",
    "        ax.set_xticklabels([m.replace(\"_\", \" \").title() for m in metrics_to_plot])\n",
    "        ax.legend()\n",
    "        ax.set_ylim(0, 1.1)\n",
    "\n",
    "        # Add labels to all bars\n",
    "        ax.bar_label(rects1, padding=3, fmt=\"%.3f\")\n",
    "        ax.bar_label(rects2, padding=3, fmt=\"%.3f\")\n",
    "        ax.bar_label(rects3, padding=3, fmt=\"%.3f\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#plot confusion matricies\n",
    "print(\"\\nPlotting Confusion Matrices...\")\n",
    "if \"all_results\" not in locals() or not isinstance(all_results, dict):\n",
    "    print(\"Error: `all_results` dictionary not found or invalid. Cannot plot confusion matrices.\")\n",
    "else:\n",
    "    model_names = list(all_results.keys())\n",
    "    num_models = len(model_names)\n",
    "    valid_plot = True\n",
    "    cms_to_plot = {}\n",
    "    for model in model_names:\n",
    "        if model not in all_results or \"confusion_matrix\" not in all_results[model]:\n",
    "            print(f\"Warning: Confusion matrix not found for model \t'{model}\t' in all_results. Skipping its matrix plot.\")\n",
    "            break\n",
    "        else:\n",
    "            cms_to_plot[model] = all_results[model][\"confusion_matrix\"]\n",
    "            \n",
    "    num_valid_cms = len(cms_to_plot)\n",
    "\n",
    "    if num_valid_cms > 0:\n",
    "        fig, axes = plt.subplots(1, num_valid_cms, figsize=(7 * num_valid_cms, 6)) \n",
    "        if num_valid_cms == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        plot_idx = 0\n",
    "        for model_name, cm in cms_to_plot.items():\n",
    "            if cm is not None and isinstance(cm, np.ndarray):\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[plot_idx],\n",
    "                            xticklabels=range(num_classes), yticklabels=range(num_classes)) \n",
    "                axes[plot_idx].set_title(f\"{model_name} Confusion Matrix\")\n",
    "                axes[plot_idx].set_xlabel(\"Predicted Label\")\n",
    "                axes[plot_idx].set_ylabel(\"True Label\")\n",
    "                plot_idx += 1\n",
    "            else:\n",
    "                 print(f\"Skipping invalid confusion matrix data for {model_name}.\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No valid confusion matrices found to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec48040-839f-4cb4-a69c-5ff6cc1b9f70",
   "metadata": {},
   "source": [
    "## Interpreting Model Performance\n",
    "\n",
    "This section is crucial for presenting and interpreting the findings from your model evaluations. It should go beyond simply stating the metrics and delve into what they mean in the context of your seismic interpretation task.\n",
    "\n",
    "**(Ensure all plots and metrics mentioned below are generated by your code cells and displayed in the notebook before this markdown section.)**\n",
    "\n",
    "### Performance of Individual Models\n",
    "\n",
    "**1. 3D CNN Model:**\n",
    "*   **Training History:** Discuss the learning curves (loss and accuracy vs. epochs for both training and validation sets). Look for signs of overfitting (large gap between training and validation performance), underfitting (both training and validation performance are low), or good convergence.\n",
    "*   **Validation Metrics:** Present the final accuracy, precision, recall, and F1-score on the validation set. Interpret these scores. For instance, what does the precision for a specific facies tell you? What about recall?\n",
    "*   **Confusion Matrix:** Analyze the confusion matrix. Which facies are well-classified? Which ones are commonly confused with each other? Provide geological or data-driven hypotheses for these confusions (e.g., subtle acoustic differences, imbalanced class representation, ambiguous labeling).\n",
    "\n",
    "**2. BiLSTM Model:**\n",
    "*   **Training History:** Similar to the CNN, discuss its learning curves.\n",
    "*   **Validation Metrics:** Present and interpret its performance metrics on the validation set.\n",
    "*   **Confusion Matrix:** Analyze its confusion matrix, comparing its strengths and weaknesses to the CNN.\n",
    "\n",
    "### Performance of the Hybrid CNN-BiLSTM Model\n",
    "\n",
    "*   **Training History:** Discuss the learning curves for the hybrid model.\n",
    "*   **Validation Metrics:** Present the final accuracy, precision, recall, and F1-score. Critically compare these to the individual CNN and BiLSTM model performances. Did the hybrid model achieve the hypothesized improvement? By how much?\n",
    "*   **Confusion Matrix:** Analyze the hybrid model's confusion matrix. Did it resolve some of the confusions observed in the individual models? Are there new patterns of misclassification?\n",
    "\n",
    "### Comparative Analysis\n",
    "\n",
    "*   **Overall Comparison Table/Plot:** Include a table or bar chart (as generated by your plotting code) that directly compares the key metrics (Accuracy, Precision, Recall, F1-score) across all three models (CNN, BiLSTM, Hybrid) on the validation set.\n",
    "*   **Statistical Significance (Optional but Recommended for Rigorous Research):** If feasible, consider performing statistical tests (e.g., McNemar's test for comparing two classifiers, or ANOVA for multiple) to determine if the performance differences between models are statistically significant.\n",
    "*   **Discussion of Strengths and Weaknesses:** Based on the results, discuss the relative strengths and weaknesses of each approach. For example:\n",
    "    *   Did the 3D CNN excel at capturing certain types of spatial features that the BiLSTM missed?\n",
    "    *   Was the BiLSTM better at distinguishing facies with subtle vertical variations along traces?\n",
    "    *   How did the hybrid model balance or improve upon these aspects?\n",
    "*   **Error Analysis:** Go deeper into specific examples of misclassifications if possible. Visualizing some misclassified patches/traces alongside their true and predicted labels can provide valuable insights into why the models made errors.\n",
    "\n",
    "### Answering Research Questions\n",
    "\n",
    "Explicitly revisit your research questions (stated in the Introduction/Methodology) and discuss how the results address them. For example:\n",
    "*   How effective are deep learning models (specifically your CNN, BiLSTM, and Hybrid) for automated seismic facies classification in the F3 block?\n",
    "*   Does the hybrid approach combining spatial and sequential feature extraction offer superior performance compared to individual models?\n",
    "\n",
    "**(Ensure this section is rich with interpretation and connects back to the geological context of the F3 dataset.)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e764209",
   "metadata": {},
   "source": [
    "### Performance Comparison\n",
    "\n",
    "*(Note: The following discussion assumes hypothetical results. Actual results from running the code should replace this.)*\n",
    "\n",
    "The 3D CNN model achieved a validation accuracy of approximately **[Insert CNN Accuracy, e.g., 0.6821]** and a weighted F1-score of **[Insert CNN F1, e.g., 0.6750]**. The confusion matrix (Figure 2a) shows **[Describe CNN CM - e.g., good performance on class X, confusion between classes Y and Z]**.\n",
    "\n",
    "The BiLSTM model, operating on individual traces, achieved an accuracy of **[Insert BiLSTM Accuracy, e.g., 0.6255]** and an F1-score of **[Insert BiLSTM F1, e.g., 0.6180]**. Its confusion matrix (Figure 2b) indicates **[Describe BiLSTM CM - e.g., struggles with class A, better at class B compared to CNN]**.\n",
    "\n",
    "**Table 2: Model Performance Summary**\n",
    "\n",
    "| Model   | Accuracy | Precision (w) | Recall (w) | F1-Score (w) |\n",
    "| :------ | :------- | :------------ | :--------- | :----------- |\n",
    "| 3D CNN  | [CNN Acc]  | [CNN Prec]    | [CNN Rec]  | [CNN F1]     |\n",
    "| BiLSTM  | [BiLSTM Acc]| [BiLSTM Prec] | [BiLSTM Rec]| [BiLSTM F1]  |\n",
    "\n",
    "*(Replace bracketed values with actual results)*\n",
    "\n",
    "Comparing the two models (Figure 1), the 3D CNN appears to slightly outperform the BiLSTM on this dataset based on overall accuracy and F1-score. This suggests that, for this specific task and data representation, analyzing the 3D spatial context within patches might be more informative than analyzing individual 1D trace sequences alone.\n",
    "\n",
    "### Relation to Research Questions\n",
    "\n",
    "1.  **CNN Effectiveness:** The 3D CNN demonstrated moderate effectiveness, achieving an accuracy significantly better than random chance but falling short of high performance (e.g., >90%). This indicates that while 3D patches contain useful information, the simple CNN architecture used might not be sufficient to fully capture the complex variations defining the facies, or the data itself might be inherently challenging. The discrepancy noted in the professor's feedback (claim of 90% vs. actual ~66%) has been corrected; the model achieves around **[Reiterate CNN Accuracy]**.\n",
    "2.  **BiLSTM Competitiveness:** The BiLSTM model provided a reasonable baseline but did not outperform the CNN. This suggests that, at least with this implementation (using single traces), the sequential information alone might be less discriminative than the 3D spatial information captured by the CNN. Further investigation could explore using multiple traces per location or different sequence representations for the BiLSTM.\n",
    "\n",
    "### Limitations and Caveats\n",
    "\n",
    "It is important to acknowledge the limitations of this study:\n",
    "*   **Simple Architectures:** The CNN and BiLSTM models used are relatively basic. More complex architectures or hyperparameter tuning might yield better results.\n",
    "*   **Single Dataset:** Findings are based solely on the F3 block dataset and may not generalize to other geological settings.\n",
    "*   **Trace Representation for BiLSTM:** The method of extracting and representing traces for the BiLSTM was simple (single random trace per patch location). More sophisticated feature extraction or sequence representation might improve BiLSTM performance.\n",
    "*   **Preprocessing Impact:** The specific preprocessing steps (filtering, normalization) can influence model performance.\n",
    "*   **Horizon Accuracy:** The analysis relies on the accuracy of the provided horizon interpretations.\n",
    "\n",
    "The results should be interpreted with caution. While the CNN showed slightly better performance here, neither model achieved exceptionally high accuracy, indicating the task remains challenging. The choice between spatial (CNN) and sequential (BiLSTM) approaches may depend on the specific geological context and data characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1878e6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This study explored the automation of seismic facies classification on the F3 block dataset using two deep learning approaches: a 3D CNN operating on seismic patches and a BiLSTM operating on seismic traces. The preprocessing pipeline successfully transformed raw SEG-Y and horizon data into labeled inputs for both models.\n",
    "\n",
    "Our results indicate that the 3D CNN achieved slightly better performance (Accuracy: **[CNN Acc]**, F1: **[CNN F1]**) compared to the BiLSTM (Accuracy: **[BiLSTM Acc]**, F1: **[BiLSTM F1]**) under the tested configurations. This suggests that leveraging 3D spatial context might be more advantageous for this specific classification task than relying solely on 1D sequential patterns within individual traces.\n",
    "\n",
    "However, neither model achieved high-end performance, highlighting the inherent complexity of seismic facies classification. Future work could explore:\n",
    "*   More advanced CNN architectures (e.g., ResNets adapted for 3D).\n",
    "*   Hybrid models combining CNN features with RNNs/Transformers.\n",
    "*   Improved sequence representations for the BiLSTM (e.g., using multiple traces, incorporating spatial location encoding).\n",
    "*   Hyperparameter optimization and data augmentation techniques.\n",
    "*   Testing on different datasets and geological settings.\n",
    "\n",
    "This work provides a baseline comparison between spatial and sequential deep learning approaches for seismic facies classification, contributing to the ongoing effort to develop more efficient and objective interpretation workflows in geophysics.\n",
    "\n",
    "*(Remember to replace placeholders like [Citation Needed] and bracketed metric values with actual information.)*\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
